{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5341fd18-08ef-4312-9806-0a363b58d379",
   "metadata": {},
   "source": [
    "## Dealing with categorical features\n",
    "+ scikit-learn will not accept categorical features by default\n",
    "+ Need to convert categorical features into numeric values\n",
    "+ Convert to binary features called dummy variables\n",
    "  - **0:** means that the observation was not in that category\n",
    "  - **1:** means that the observation was that category"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dd1b5e6-1b18-4831-bd14-9c3b7ae8caee",
   "metadata": {},
   "source": [
    "![dummy-variable](supervised-learning/images/dummy-variable-1.png)\n",
    "![dummy-variable](supervised-learning/images/dummy-variable-1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73075a51-6442-4b9d-aee6-ac4ee14feed1",
   "metadata": {},
   "source": [
    "## Dealing with categorical features in Python\n",
    "+ scikit-learn: OneHotEncoder()\n",
    "+ pandas: get_dummies()\n",
    "\n",
    "### Encoding dummy variables\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "music_df = pd.read_csv('music.csv')\n",
    "music_dummies = pd.get_dummies(music_df[\"genre\"], drop_first=True)\n",
    "\n",
    "music_dummies = pd.concat(music_df, music_dummies, axis=1)\n",
    "music_dummies = music_dummies.drop('genre', axis=1)\n",
    "\n",
    "\n",
    "# Create X and y\n",
    "X = music_dummies.drop(\"popularity\", axis=1)\n",
    "y = music_dummies[\"popularity\"]\n",
    "\n",
    "# Instantiate a ridge model\n",
    "ridge = Ridge(alpha=0.2)\n",
    "\n",
    "# Perform cross-validation\n",
    "scores = cross_val_score(ridge, X, y, cv=kf, scoring=\"neg_mean_squared_error\")\n",
    "\n",
    "# Calculate RMSE\n",
    "rmse = np.sqrt(-scores)\n",
    "print(\"Average RMSE: {}\".format(np.mean(rmse)))\n",
    "print(\"Standard Deviation of the target array: {}\".format(np.std(y)))\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "246a0bb5-7dc3-4b4c-b8a1-83bc984a46ee",
   "metadata": {},
   "source": [
    "## Handling Missing Data\n",
    "\n",
    "+ Dropping missing data\n",
    "\n",
    "```python\n",
    "\n",
    "print(music_df.isna().sum().sort_values())\n",
    "\n",
    "# Remove values where less than 5% are missing\n",
    "music_df = music_df.dropna(subset=[\"genre\", \"popularity\", \"loudness\", \"liveness\", \"tempo\"])\n",
    "```\n",
    "\n",
    "### Imputing values\n",
    "+ Imputation - use subject-matter expertise to replace missing data with educated guesses\n",
    "+ Common to use the mean\n",
    "+ Can also use the median, or another value\n",
    "+ For categorical values, we typically use the most frequent value - the mode\n",
    "+ Must split our data first, to avoid data leakage\n",
    "\n",
    "```python\n",
    "\n",
    "# Print missing values for each column\n",
    "print(music_df.isna().sum().sort_values())\n",
    "\n",
    "# Remove values where less than 5% are missing\n",
    "music_df = music_df.dropna(subset=[\"genre\", \"popularity\", \"loudness\", \"liveness\", \"tempo\"])\n",
    "\n",
    "# Convert genre to a binary feature\n",
    "music_df[\"genre\"] = np.where(music_df[\"genre\"] == \"Rock\", 1, 0)\n",
    "\n",
    "print(music_df.isna().sum().sort_values())\n",
    "print(\"Shape of the `music_df`: {}\".format(music_df.shape))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c86c6fd1-2344-42dd-b16a-5fc70f659de1",
   "metadata": {},
   "source": [
    "## Pipeline for song genre prediction\n",
    "\n",
    "Now it's time to build a pipeline. It will contain steps to impute missing values using the mean for each feature and build a KNN model for the classification of song genre.\n",
    "\n",
    "```python\n",
    "# Import modules\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Instantiate an imputer\n",
    "imputer = SimpleImputer()\n",
    "\n",
    "# Instantiate a knn model\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "# Build steps for the pipeline\n",
    "steps = [(\"imputer\", imputer), (\"knn\", knn)]\n",
    "\n",
    "# Create the pipeline\n",
    "pipeline = Pipeline(steps)\n",
    "\n",
    "# Fit the pipeline to the training data\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# Print the confusion matrix\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad993e1-d245-4977-b7c9-212d447b4521",
   "metadata": {},
   "source": [
    "## Imputing within a pipeline\n",
    "\n",
    "```python\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "music_df = music_df.dropna(subset=[\"genre\", \"popularity\", \"loudness\", \"liveness\", \"tempo\"])\n",
    "music_df[\"genre\"] = np.where(music_df[\"genre\"] == \"Rock\", 1, 0)\n",
    "X = music_df.drop(\"genre\", axis=1).values\n",
    "y = music_df[\"genre\"].values\r\n",
    "steps = [(\"imputation\", SimpleImputer()), (\"logistic_regression\", LogisticRegression)]\n",
    "\n",
    "pipeline = Pipeline(steps)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "pipeline.fit(X_train, y_train)\n",
    "pipeline.score(X_test, y_test\n",
    "\n",
    "# Build the steps\r\n",
    "steps = [(\"scaler\", StandardScaler()),\r\n",
    "         (\"logreg\", LogisticRegression())]\r\n",
    "pipeline = Pipeline(steps)\r\n",
    "\r\n",
    "# Create the parameter space\r\n",
    "parameters = {\"logreg__C\": np.linspace(0.001, 1.0, 20)}\r\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, \r\n",
    "                                                    random_state=21)\r\n",
    "\r\n",
    "# Instantiate the grid search object\r\n",
    "cv = GridSearchCV(pipeline, param_grid=parameters)\r\n",
    "\r\n",
    "# Fit to the training data\r\n",
    "cv.fit(X_train, y_train)\r\n",
    "print(cv.best_score_, \"\\n\", cv.best_params_)\n",
    "```\r\n",
    "\n",
    "                                    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eaa5305-2a37-45d4-b459-7f20897776e8",
   "metadata": {},
   "source": [
    "## Visualizing regression model performance\n",
    "\n",
    "```python\n",
    "\n",
    "models = {\"Linear Regression\": LinearRegression(), \"Ridge\": Ridge(alpha=0.1), \"Lasso\": Lasso(alpha=0.1)}\n",
    "results = []\n",
    "\n",
    "# Loop through the models' values\n",
    "for model in models.values():\n",
    "  kf = KFold(n_splits=6, random_state=42, shuffle=True)\n",
    "  \n",
    "  # Perform cross-validation\n",
    "  cv_scores = cross_val_score(model, X_train, y_train, cv=kf)\n",
    "  \n",
    "  # Append the results\n",
    "  results.append(cv_scores)\n",
    "\n",
    "# Create a box plot of the results\n",
    "plt.boxplot(results, labels=models.keys())\n",
    "plt.show()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d33353d2-7672-4815-bb6e-d5f2d2b1f6dd",
   "metadata": {},
   "source": [
    "```python\n",
    "# Import mean_squared_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "for name, model in models.items():\n",
    "  \n",
    "  # Fit the model to the training data\n",
    "  model.fit(X_train_scaled, y_train)\n",
    "  \n",
    "  # Make predictions on the test set\n",
    "  y_pred = model.predict(X_test_scaled)\n",
    "  \n",
    "  # Calculate the test_rmse\n",
    "  test_rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "  print(\"{} Test Set RMSE: {}\".format(name, test_rmse))\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "254df57f-af05-4d0c-a784-58e397ac7291",
   "metadata": {},
   "source": [
    "## Visualizing classification model performance\n",
    "\n",
    "```python\n",
    "# Create models dictionary\n",
    "models = {\"Logistic Regression\": LogisticRegression(), \"KNN\": KNeighborsClassifier(), \"Decision Tree Classifier\": DecisionTreeClassifier()}\n",
    "results = []\n",
    "\n",
    "# Loop through the models' values\n",
    "for model in models.values():\n",
    "  \n",
    "  # Instantiate a KFold object\n",
    "  kf = KFold(n_splits=6, random_state=12, shuffle=True)\n",
    "  \n",
    "  # Perform cross-validation\n",
    "  cv_results = cross_val_score(model, X_train, y_train, cv=kf)\n",
    "  results.append(cv_results)\n",
    "plt.boxplot(results, labels=models.keys())\n",
    "plt.show()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13fe9e9b-0054-417b-8ed5-efd6a2ffbc65",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
